{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fb84e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.25\n",
      "1    0.50\n",
      "2    0.75\n",
      "3    1.00\n",
      "dtype: float64\n",
      "\n",
      " Auswahl von Element aus dem Series-Objekt\n",
      "[0.25 0.5  0.75 1.  ]\n",
      "RangeIndex(start=0, stop=4, step=1)\n",
      "1    0.50\n",
      "2    0.75\n",
      "dtype: float64\n",
      "\n",
      "Umbenannte Indizes\n",
      " a    0.25\n",
      "b    0.50\n",
      "c    0.75\n",
      "d    1.00\n",
      "dtype: float64 0.25\n",
      "\n",
      "Series from Dictionairy\n",
      " California    38332521\n",
      "Texas         26448193\n",
      "New York      19651127\n",
      "Florida       19552860\n",
      "Illinois      22882135\n",
      "dtype: int64\n",
      "California    38332521\n",
      "Texas         26448193\n",
      "New York      19651127\n",
      "dtype: int64\n",
      "California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "dtype: int64\n",
      "\n",
      "X Dataframe\n",
      "            population    area\n",
      "California    38332521  423967\n",
      "Texas         26448193  695662\n",
      "New York      19651127  141297\n",
      "Florida       19552860  170312\n",
      "Illinois      22882135  149995\n",
      "states.columns Index(['population', 'area'], dtype='object')\n",
      "\n",
      "states['area']:\n",
      " California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "Name: area, dtype: int64\n",
      "\n",
      " states['area']['California']: 423967\n",
      "\n",
      " states.area:\n",
      " California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "Name: area, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# XX Kapitel 3: Data Manipulation with Pandas\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas\n",
    "\n",
    "# Pandas ist ein neues Paket, das auf Numpy aufbaut und den Datentyp DataFrame implementiert, der in der Regel multidimensionale\n",
    "# Arrays mit Spalten- und Zeilenlabel, unterschiedlichen Datentypen und fehlenden Werten umfasst\n",
    "# >> Panda stellt außerdem eine VIelzahl von Funktionen bereit, mit denen Daten für die nachträgliche Analyse aufbereitet werden \n",
    "#    können\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# X Fundamentale Datentypen in Pandas\n",
    "\n",
    "# - Series-Objekte\n",
    "# ... sind eindimensionale Arrays, die aus einer Liste oder einem array erstellt werden können\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "print(data)\n",
    "\n",
    "# Das Objekt enthält Indexe (Typ: pd.Index) und Werte (Typ: np.array), die ausgewählt werden können\n",
    "print(\"\\n Auswahl von Element aus dem Series-Objekt\")\n",
    "print(data.values)\n",
    "print(data.index)\n",
    "\n",
    "# Auswahl mit [] möglich\n",
    "print(data[1:3])\n",
    "\n",
    "# >> im Gegensatz zu einem eindimensionalen np.array wird der INdex des pd.Series-Objekt explizit und nicht implizit definiert\n",
    "# >> Dadurch kann ein Index auch umbenannt werden (e.g in Strings oder unkontinuierliche Zahlenreihen 0, 5, 6, 9 etc.)\n",
    "\n",
    "data=pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "              index = ['a', 'b', 'c', 'd'])\n",
    "print(\"\\nUmbenannte Indizes\\n\",data, data['a'])\n",
    "\n",
    "# -> Series-Objekte sind im Prinzip eine Spzialisierung des Python Dicitonairies\n",
    "# >> im Gegensatz zum Dictionairy, das arbiträre Datentypen verwendet, nutzt das Series-Objekt typisierte Werte für Idx und Values\n",
    "\n",
    "population_dict = {'California': 38332521,\n",
    "                  'Texas': 26448193,\n",
    "                  'New York': 19651127,\n",
    "                  'Florida': 19552860,\n",
    "                  'Illinois': 22882135}\n",
    "\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "print(\"\\nSeries from Dictionairy\\n\", population)\n",
    "print(population['California': 'New York'])\n",
    "\n",
    "\n",
    "# - Pandas DataFrame-Objekte\n",
    "# ... können als eine Generalisierung von NumPy Arrays oder als Spezialisierung von Dictionairies betrachtet werden\n",
    "\n",
    "# Ein DataFrame ist ein zwei-dimensionaler NumPy Array mit flexibler Indexierung und Spaltennamen\n",
    "# Er kann als Kombination von aufeinander ausgerichteten (gleicher Index in Reihe) Series-Objekten gesehen werden\n",
    "area_dict = {'California': 423967,\n",
    "             'Texas': 695662,\n",
    "             'New York': 141297,\n",
    "             'Florida': 170312,\n",
    "             'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "print(area)\n",
    "\n",
    "states = pd.DataFrame({'population':population,\n",
    "                      'area':area})\n",
    "print(\"\\nX Dataframe\")\n",
    "print(states)\n",
    "# Das Dataframe-Objekt hat ein .index und ein .columns-Attribut\n",
    "print(\"states.columns\", states.columns)\n",
    "print(\"\\nstates['area']:\\n\", states['area'])\n",
    "print(\"\\n states['area']['California']:\", states['area']['California'])\n",
    "print(\"\\n states.area:\\n\",states.area)\n",
    "\n",
    "# Dataframes können aus einem einzelnen Series-objekt erstellt werden pd.DataFrame(Series, colum=['name']), oder aus einer Liste\n",
    "# aus Dictionären, oder aus einem Dictionär von Serienobjekten [siehe oben], von einem zwei-dimensionalen Numpy array \n",
    "# (pd.Dataframe(np.random.rand(3,2), columns = ['name1', 'name2'], index = [\"a\", \"b\", \"c\"]) oder von einem structured Numpy Array\n",
    "\n",
    "\n",
    "# - Pandas Index-Objekte\n",
    "# ... Indexe können entweder ein immutable Array (können nicht verändert werden) oder als geordnetes Set (Logische Operationen\n",
    "#     wie Schnittmengen etc. funktionieren) werden gesehen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6fc30b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selektion in Series-Objekten\n",
      "a    0.25\n",
      "b    0.50\n",
      "c    0.75\n",
      "d    1.00\n",
      "dtype: float64\n",
      "\n",
      "data['a']: 0.25\n",
      "True\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "[('a', 0.25), ('b', 0.5), ('c', 0.75), ('d', 1.0)]\n",
      "a    0.25\n",
      "b    0.50\n",
      "c    0.75\n",
      "d    1.00\n",
      "e    1.25\n",
      "dtype: float64\n",
      "\n",
      " Slicing Auswahl über Indexrange\n",
      "data['b':'d']:\n",
      " b    0.50\n",
      "c    0.75\n",
      "d    1.00\n",
      "dtype: float64\n",
      "data[0:2]:\n",
      " a    0.25\n",
      "b    0.50\n",
      "dtype: float64\n",
      "\n",
      " Masking mit logischem Auswahlkriterium\n",
      "data[data > 0.7]:\n",
      " c    0.75\n",
      "d    1.00\n",
      "e    1.25\n",
      "dtype: float64\n",
      "\n",
      "Probleme beim Indexing\n",
      "data[1]: a\n",
      "data[1:3]:\n",
      " 3    b\n",
      "5    c\n",
      "dtype: object\n",
      "data.loc[1:3]:\n",
      " 1    a\n",
      "3    b\n",
      "dtype: object\n",
      "data.iloc[1:3]:\n",
      " 3    b\n",
      "5    c\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Selektion in DataFrame Objekten\n",
      "\n",
      "California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "Name: area, dtype: int64\n",
      "\n",
      " California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "Name: area, dtype: int64\n",
      "\n",
      "               area       pop     density\n",
      "California  423967  38332521   90.413926\n",
      "Texas       695662  26448193   38.018740\n",
      "New York    141297  19651127  139.076746\n",
      "Florida     170312  19552860  114.806121\n",
      "Illinois    149995  22882135  152.552652\n",
      "\n",
      " [[4.23967000e+05 3.83325210e+07 9.04139261e+01]\n",
      " [6.95662000e+05 2.64481930e+07 3.80187404e+01]\n",
      " [1.41297000e+05 1.96511270e+07 1.39076746e+02]\n",
      " [1.70312000e+05 1.95528600e+07 1.14806121e+02]\n",
      " [1.49995000e+05 2.28821350e+07 1.52552652e+02]]\n",
      "\n",
      "            California         Texas      New York       Florida      Illinois\n",
      "area     4.239670e+05  6.956620e+05  1.412970e+05  1.703120e+05  1.499950e+05\n",
      "pop      3.833252e+07  2.644819e+07  1.965113e+07  1.955286e+07  2.288214e+07\n",
      "density  9.041393e+01  3.801874e+01  1.390767e+02  1.148061e+02  1.525527e+02\n",
      "\n",
      "               area       pop\n",
      "California  423967  38332521\n",
      "Texas       695662  26448193\n",
      "New York    141297  19651127\n",
      "\n",
      "               area       pop\n",
      "California  423967  38332521\n",
      "Texas       695662  26448193\n",
      "\n",
      "                pop    area\n",
      "New York  19651127  141297\n",
      "Florida   19552860  170312\n",
      "Illinois  22882135  149995\n"
     ]
    }
   ],
   "source": [
    "# X Indexing und Selektion von Werten\n",
    "data=pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "              index = ['a', 'b', 'c', 'd'])\n",
    "\n",
    "# - Series-Objekte\n",
    "print(\"Selektion in Series-Objekten\")\n",
    "print(data)\n",
    "# Werte mit Index Selektieren\n",
    "print(\"\\ndata['a']:\", data[\"a\"])\n",
    "\n",
    "# Außerdem funktionieren Dictionairy-Like Expression\n",
    "print(\"a\" in data)\n",
    "print(data.keys())\n",
    "print(list(data.items()))\n",
    "\n",
    "# Objekte können wie in einem Dictionairy ergänzt werden\n",
    "data[\"e\"] = 1.25\n",
    "print(data)\n",
    "\n",
    "# Slicing\n",
    "print(\"\\n Slicing Auswahl über Indexrange\")\n",
    "print(\"data['b':'d']:\\n\", data['b':'d']) # beinhaltet finalen Index\n",
    "print(\"data[0:2]:\\n\", data[0:2]) # implizierter numerischer Zeilenindex\n",
    "\n",
    "# Masking\n",
    "print(\"\\n Masking mit logischem Auswahlkriterium\")\n",
    "print(\"data[data > 0.7]:\\n\", data[data > 0.7])\n",
    "\n",
    "# Herausforderung von Indexierung\n",
    "data = pd.Series([\"a\", \"b\", \"c\"], index=[1, 3, 5])\n",
    "print(\"\\nProbleme beim Indexing\")\n",
    "print(\"data[1]:\", data[1]) # basiert auf expliziter Indexierung\n",
    "print(\"data[1:3]:\\n\", data[1:3]) # basiert auf impliziter Indexierung von 0-2\n",
    "\n",
    "# >> Lösung .loc(explizite Indizes) und .iloc(implizite Indizes)-Methoden\n",
    "print(\"data.loc[1:3]:\\n\", data.loc[1:3]) # verwendet die festgelegten Indizes\n",
    "print(\"data.iloc[1:3]:\\n\", data.iloc[1:3]) # verwendet die impliziten Indizes\n",
    "\n",
    "\n",
    "# - DataFrame Objekte\n",
    "print(\"\\n\\nSelektion in DataFrame Objekten\\n\")\n",
    "\n",
    "pop = pd.Series({'California': 38332521,\n",
    "                  'Texas': 26448193,\n",
    "                  'New York': 19651127,\n",
    "                  'Florida': 19552860,\n",
    "                  'Illinois': 22882135})\n",
    "area = pd.Series({'California': 423967,\n",
    "                    'Texas': 695662,\n",
    "                    'New York': 141297,\n",
    "                    'Florida': 170312,\n",
    "                    'Illinois': 149995})\n",
    "data = pd.DataFrame({'area':area, 'pop': pop})\n",
    "\n",
    "# Auswahl der Series-Obekte über die Dictionairy Keys\n",
    "print(data['area']) # >> bessere Form der Auswahl\n",
    "# Alternative Auswahl mit .\n",
    "print(\"\\n\",data.area)\n",
    "\n",
    "# Berechnung neuer Spalten\n",
    "data['density'] = data['pop']/data['area']\n",
    "print(\"\\n\", data)\n",
    "\n",
    "# Da DataFrames, wie structured arrays gedacht werden können, kann man deren Methoden verwenden\n",
    "print(\"\\n\", data.values) # gibt die Werte aus\n",
    "print(\"\\n\", data.T) # Transposed die Matrix\n",
    "\n",
    "# Um auf ein DataFrame-Objekt, wie bei einen NumPy Array mit Zeilen- und Spaltenindex [] zugreifen zu können, muss iloc[] verwendet werden\n",
    "print(\"\\n\", data.iloc[:3, :2])\n",
    "print(\"\\n\", data.loc[:\"Texas\", :\"pop\"]) # mit loc können die Zeilen- und Spaltennamen verwendet werden\n",
    "\n",
    "# Kann mit fancy-Indexing und Masking combiniert werden\n",
    "print(\"\\n\",data.loc[data['density'] > 100, ['pop', 'area']]) # gibt Pop und Area für alle Zeilen aus, bei denen density > 100\n",
    "\n",
    "# >> Jede dieser Konventionen kann verwendet werden, um einzelne Werte zu überschreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7aaa54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6\n",
      "1    3\n",
      "2    7\n",
      "3    4\n",
      "dtype: int32\n",
      "\n",
      " Unfuncs behalten den Index, e.g. np.exp\n",
      " 0     403.428793\n",
      "1      20.085537\n",
      "2    1096.633158\n",
      "3      54.598150\n",
      "dtype: float64\n",
      "\n",
      "    A  B  C  D\n",
      "0  6  9  2  6\n",
      "1  7  4  3  7\n",
      "2  7  2  5  4\n",
      "\n",
      "UFuncs behalten die Label der Zeilen und Spalten\n",
      "           A             B         C             D\n",
      "0 -1.000000  7.071068e-01  1.000000 -1.000000e+00\n",
      "1 -0.707107  1.224647e-16  0.707107 -7.071068e-01\n",
      "2 -0.707107  1.000000e+00 -0.707107  1.224647e-16\n",
      "\n",
      "Index Alignment\n",
      "\n",
      "Alaska              NaN\n",
      "California    90.413926\n",
      "New York            NaN\n",
      "Texas         38.018740\n",
      "dtype: float64\n",
      "Index(['Texas', 'California'], dtype='object')\n",
      "\n",
      " Alaska          172337.0\n",
      "California    38756488.0\n",
      "New York      19651127.0\n",
      "Texas         27143855.0\n",
      "dtype: float64\n",
      "\n",
      "Dataframes\n",
      "   A   B\n",
      "0  1  11\n",
      "1  5   1\n",
      "   B  A  C\n",
      "0  4  0  9\n",
      "1  5  8  0\n",
      "2  9  2  6\n",
      "      A     B   C\n",
      "0   1.0  15.0 NaN\n",
      "1  13.0   6.0 NaN\n",
      "2   NaN   NaN NaN\n",
      "4.5\n"
     ]
    }
   ],
   "source": [
    "# X Operating on Data in Pandas\n",
    "# Pandas erlaubt viele effiziente mathematischen Operationen mit Universal Functions (NumPy)\n",
    "# und behält zusätzlich die Indexierung und Zeilen-/Spaltenlabel bei\n",
    "\n",
    "# Zunächst wird ein einfacher DataFrame und eine Series erstellt\n",
    "rng = np.random.RandomState(42)\n",
    "ser = pd.Series(rng.randint(0, 10, 4))\n",
    "print(ser)\n",
    "print(\"\\n Unfuncs behalten den Index, e.g. np.exp\\n\", np.exp(ser))\n",
    "\n",
    "df = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n",
    "                 columns = ['A', 'B', 'C', 'D'])\n",
    "print(\"\\n\", df)\n",
    "print(\"\\nUFuncs behalten die Label der Zeilen und Spalten\\n\", np.sin(df * np.pi /4))\n",
    "\n",
    "# Index Alignment\n",
    "print(\"\\nIndex Alignment\\n\")\n",
    "area = pd.Series({'Alaska': 172337, 'Texas': 695662, 'California': 423967}, name='area')\n",
    "population = pd.Series({'California': 38332521, 'Texas': 26448193, 'New York': 19651127}, name='population')\n",
    "print(population/area)\n",
    "\n",
    "# Python nutzt automatisch Schnittmengen, um zu Überprüfen, ob die Indexe übereinstimmen (nur dann wird ein Wert berechnet)\n",
    "# Allen anderen wird NaN zugewiesen\n",
    "print(area.index.intersection(population.index))\n",
    "\n",
    "# MIt einem fill-Value kann die KOdierung als NaN umgegangen werden\n",
    "print(\"\\n\",area.add(population, fill_value=0))\n",
    "\n",
    "\n",
    "# Index Alignment in DataFrames\n",
    "print(\"\\nDataframes\")\n",
    "A = pd.DataFrame(rng.randint(0, 20, (2, 2)),\n",
    "                columns=list('AB'))\n",
    "print(A)\n",
    "\n",
    "B = pd.DataFrame(rng.randint(0, 10, (3,3)),\n",
    "                columns=list('BAC'))\n",
    "print(B)\n",
    "# Auch hier funktioniert Index Alignment\n",
    "print(A.add(B))\n",
    "print(A.stack().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dcb6ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- None\n",
      "[1 None 3 4] object\n",
      "\n",
      "-NaN\n",
      "[ 1. nan  3.  4.] float64\n",
      "nan nan nan nan\n",
      "8.0 1.0 4.0\n",
      "0    1.0\n",
      "1    NaN\n",
      "2    2.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "\n",
      "Fehlende Werte erkennen\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "       0      1      2     3\n",
      "0  False   True  False  True\n",
      "1  False  False  False  True\n",
      "2   True  False  False  True\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n",
      "\n",
      " Fehlende Werte entfernen\n",
      "0    1.0\n",
      "2    2.0\n",
      "dtype: float64\n",
      "   2\n",
      "0  2\n",
      "1  4\n",
      "2  6\n",
      "     0    1  2\n",
      "0  1.0  NaN  2\n",
      "1  2.0  3.0  4\n",
      "2  NaN  5.0  6\n",
      "     0    1  2   3\n",
      "1  2.0  3.0  4 NaN nur Zeile 1 hat 3 Werte\n",
      "\n",
      "Fehlende Werte füllen\n",
      "0       1.0\n",
      "1   -9999.0\n",
      "2       2.0\n",
      "3   -9999.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# X Handling Missing Data\n",
    "# Fehlende Werte können von Programmen auf zwei unterschiedliche Weisen gehandhabt werden\n",
    "# - Entweder wird ein weiterer zum overhead jeder Zelle zugeteilt, der mit einer Bolean repräsentiert, ob ein Wert enthalten ist oder nicht\n",
    "# - Oder es wird ein bestimmter Wert (NA, NaN, -9999) zugewiesen, was allerdings den Wertebereich einer Variable einschränkt\n",
    "\n",
    "# >> In Panda werden zwei exisitierende Repräsentation von fehlenden Werten gewählt um diese anzuzeigen > NaN und None\n",
    "\n",
    "# Das None-Objekt\n",
    "print(\"- None\")\n",
    "vals = np.array([1, None, 3, 4])\n",
    "print(vals, vals.dtype) # Der array ist vom Objekt Typ, da None von der Python-Objekt Klasse ist, was die Brechnungen stark verlangsamt\n",
    "# vals.sum() gibt außerdem einen type-Error, da int + None nicht definiert ist\n",
    "\n",
    "# NaN- Missing numerical Data\n",
    "print(\"\\n-NaN\")\n",
    "vals2 = np.array([1, np.nan, 3, 4]) # Datentyp ist float, da NaN ein besonderer Float-Value ist, der einen fehlenden Wert anzeigt\n",
    "print(vals2, vals2.dtype)\n",
    "# >> Alle Rechenoperationen mit nan ergeben nan >> aber keinen Error\n",
    "print(0*np.nan, vals2.sum(), vals2.min(), vals2.max())\n",
    "\n",
    "# Es gibt einige besondere Funktionen, bei denen diese fehlenden Werte ignoriert werden\n",
    "print(np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2))\n",
    "\n",
    "# - NaN und None in Pandas\n",
    "srs = pd.Series([1, np.nan, 2, None])\n",
    "df = pd.DataFrame([[1, np.nan, 2, np.nan],\n",
    "                  [2,  3,      4, np.nan],\n",
    "                  [np.nan, 5,  6, np.nan]])\n",
    "print(srs) # automatisch wandelt integers in floats, um NaN benennen zu können\n",
    "\n",
    "# - Fehlende Werte im Datensatz identifizieren\n",
    "print(\"\\nFehlende Werte erkennen\")\n",
    "print(srs.isnull()) # erstellt eine Bolean Mask für fehlende Werte\n",
    "print(df.isnull()) # auf für Dataframes\n",
    "print(srs.notnull())# Gegenteil von isnull\n",
    "\n",
    "print(\"\\n Fehlende Werte entfernen\")\n",
    "print(srs.dropna())\n",
    "print(df.dropna(axis='columns')) # axis bestimmt ob Zeilen oder Spalten entfernt werden sollen\n",
    "print(df.dropna(axis='columns', how='all')) \n",
    "# mit how kann bestimmt werden, welche Reihen/Spalten entfernt werden (any-mit einem NaN, all-mit Allen NaN)\n",
    "print(df.dropna(axis='rows', thresh=3), \"nur Zeile 1 hat 3 Werte\")\n",
    "# tresh gibt die mindestanzahl von tatsächlichen Werten an, die eine Spalte/Zeile haben muss, um beibehalten zu werden\n",
    "\n",
    "print(\"\\nFehlende Werte füllen\")\n",
    "print(srs.fillna(-9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "39f39688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Practice - Tuple Indexing\n",
      "(California, 2000)    33871648\n",
      "(California, 2010)    37253956\n",
      "(New York, 2000)      18976457\n",
      "(New York, 2010)      19378102\n",
      "(Texas, 2000)         20851820\n",
      "(Texas, 2010)         25145561\n",
      "dtype: int64\n",
      "\n",
      "Slicing mit multilevel Index\n",
      "(California, 2010)    37253956\n",
      "(New York, 2000)      18976457\n",
      "(New York, 2010)      19378102\n",
      "(Texas, 2000)         20851820\n",
      "dtype: int64\n",
      "\n",
      "Indexlevel Zugriff via For-Loops\n",
      "(California, 2010)    37253956\n",
      "(New York, 2010)      19378102\n",
      "(Texas, 2010)         25145561\n",
      "dtype: int64\n",
      "Good Practice - Multilevel Index\n",
      "Levels [['California', 'New York', 'Texas'], [2000, 2010]]\n",
      "MultiIndex([('California', 2000),\n",
      "            ('California', 2010),\n",
      "            (  'New York', 2000),\n",
      "            (  'New York', 2010),\n",
      "            (     'Texas', 2000),\n",
      "            (     'Texas', 2010)],\n",
      "           )\n",
      "\n",
      "X Multilevel Indexed Data\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "California    37253956\n",
      "New York      19378102\n",
      "Texas         25145561\n",
      "dtype: int64\n",
      "\n",
      "Der dazugehörige Dataframe\n",
      "                 2000      2010\n",
      "California  33871648  37253956\n",
      "New York    18976457  19378102\n",
      "Texas       20851820  25145561\n",
      "\n",
      " Variablen ergänzen\n",
      "                    total  under18\n",
      "California 2000  33871648  9267089\n",
      "           2010  37253956  9284094\n",
      "New York   2000  18976457  4687374\n",
      "           2010  19378102  4318033\n",
      "Texas      2000  20851820  5906301\n",
      "           2010  25145561  6879014\n",
      "                2000      2010\n",
      "California  0.273594  0.249211\n",
      "New York    0.247010  0.222831\n",
      "Texas       0.283251  0.273568\n",
      "\n",
      "Multiindex DataFrames erstellen\n",
      "        data1     data2\n",
      "a 1  0.212070  0.707470\n",
      "  2  0.679428  0.742884\n",
      "b 1  0.196027  0.168631\n",
      "  2  0.565786  0.455750\n",
      "MultiIndex([('a', 1),\n",
      "            ('a', 2),\n",
      "            ('b', 1),\n",
      "            ('b', 2)],\n",
      "           )\n",
      "MultiIndex([('a', 1),\n",
      "            ('a', 2),\n",
      "            ('b', 1),\n",
      "            ('b', 2),\n",
      "            ('c', 1),\n",
      "            ('c', 2)],\n",
      "           )\n",
      "\n",
      " Benannte Indexe\n",
      "                    total  under18\n",
      "state      year                   \n",
      "California 2000  33871648  9267089\n",
      "           2010  37253956  9284094\n",
      "New York   2000  18976457  4687374\n",
      "           2010  19378102  4318033\n",
      "Texas      2000  20851820  5906301\n",
      "           2010  25145561  6879014\n",
      "\n",
      " Komplexe Dataframes mit Mutli-Zeilen- und -Spalten-Index\n",
      "Subject       Bob       Guido         Sue      \n",
      "Type           HR  Temp    HR  Temp    HR  Temp\n",
      "years visit                                    \n",
      "2013  1      29.0  36.8  51.0  38.2  39.0  36.3\n",
      "      2      40.0  37.1  26.0  38.7  34.0  35.8\n",
      "2014  1      25.0  38.3  56.0  38.3  26.0  35.9\n",
      "      2      11.0  36.5  42.0  35.2  25.0  37.4\n",
      "\n",
      "Einzelne Person\n",
      " Type           HR  Temp\n",
      "years visit            \n",
      "2013  1      51.0  38.2\n",
      "      2      26.0  38.7\n",
      "2014  1      56.0  38.3\n",
      "      2      42.0  35.2\n",
      "\n",
      "Einzelnes Jahr\n",
      " Subject   Bob       Guido         Sue      \n",
      "Type       HR  Temp    HR  Temp    HR  Temp\n",
      "visit                                      \n",
      "1        29.0  36.8  51.0  38.2  39.0  36.3\n",
      "2        40.0  37.1  26.0  38.7  34.0  35.8\n",
      "\n",
      "Ein Jahr einer Person\n",
      " Type     HR  Temp\n",
      "visit            \n",
      "1      51.0  38.2\n",
      "2      26.0  38.7\n",
      "\n",
      "\n",
      "Auswahl mit Multiindex Series\n",
      "state\n",
      "California    33871648\n",
      "New York      18976457\n",
      "Texas         20851820\n",
      "dtype: int64\n",
      "\n",
      " state       year\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "Texas       2010    25145561\n",
      "dtype: int64\n",
      "\n",
      "Auswahl bei Multiindex DataFrames\n",
      "years  visit\n",
      "2013   1        39.0\n",
      "       2        34.0\n",
      "2014   1        26.0\n",
      "       2        25.0\n",
      "Name: (Sue, HR), dtype: float64\n",
      "\n",
      " years  visit\n",
      "2013   1        29.0\n",
      "       2        40.0\n",
      "2014   1        25.0\n",
      "       2        11.0\n",
      "Name: (Bob, HR), dtype: float64\n",
      "Subject       Bob Guido   Sue\n",
      "Type           HR    HR    HR\n",
      "years visit                  \n",
      "2013  1      29.0  51.0  39.0\n",
      "2014  1      25.0  56.0  26.0\n",
      "\n",
      "Multilevel Index sortieren\n",
      "char  int\n",
      "a     1      0.128124\n",
      "      2      0.457453\n",
      "c     1      0.065161\n",
      "      2      0.667600\n",
      "b     1      0.174300\n",
      "      2      0.730900\n",
      "dtype: float64\n",
      "\n",
      " char  int\n",
      "a     1      0.128124\n",
      "      2      0.457453\n",
      "b     1      0.174300\n",
      "      2      0.730900\n",
      "c     1      0.065161\n",
      "      2      0.667600\n",
      "dtype: float64\n",
      "\n",
      "Deskriptive Kennwerte\n",
      "Subject  Type\n",
      "Bob      HR      26.250\n",
      "         Temp    37.175\n",
      "Guido    HR      43.750\n",
      "         Temp    37.600\n",
      "Sue      HR      31.000\n",
      "         Temp    36.350\n",
      "dtype: float64\n",
      "Subject   Bob        Guido          Sue       \n",
      "Type       HR   Temp    HR   Temp    HR   Temp\n",
      "years                                         \n",
      "2013     34.5  36.95  38.5  38.45  36.5  36.05\n",
      "2014     18.0  37.40  49.0  36.75  25.5  36.65\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical Indexing\n",
    "# Manchmal reichen zweidimensionale Datenobjekte nicht aus\n",
    "# >> Panda bietet dafür Panel-Objekte, die drei- oder vier-dimensionale Daten umfassen können\n",
    "# >> Alternativ kann Hierarchical (oder multi-)indexing verwendet werden, um mehrere Indexlevel in einem einzigen Index zu vereinen\n",
    "\n",
    "# - Eine Multiple Index Serie\n",
    "# The Bad way\n",
    "print(\"Bad Practice - Tuple Indexing\")\n",
    "index = [(\"California\", 2000), ('California', 2010),\n",
    "         (\"New York\", 2000), ('New York', 2010),\n",
    "        (\"Texas\", 2000), ('Texas', 2010)]\n",
    "populations = [33871648, 37253956,\n",
    "              18976457, 19378102,\n",
    "              20851820, 25145561]\n",
    "\n",
    "pop = pd.Series(populations, index = index)\n",
    "print(pop)\n",
    "print(\"\\nSlicing mit multilevel Index\")\n",
    "print(pop[('California', 2010):('Texas', 2000)])\n",
    "\n",
    "print(\"\\nIndexlevel Zugriff via For-Loops\")\n",
    "print(pop[[i for i in pop.index if i[1] ==2010]])\n",
    "\n",
    "# The Good way\n",
    "print(\"Good Practice - Multilevel Index\")\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "print(\"Levels\", index.levels)\n",
    "print(index)\n",
    "\n",
    "# Multilevel indexed Data\n",
    "print(\"\\nX Multilevel Indexed Data\")\n",
    "pop = pd.Series(populations, index = index)\n",
    "print(pop)\n",
    "print(pop[:,2010]) # Zweiter Wert in [] gibt Wert des Zweiten Indexes an\n",
    "\n",
    "# mit unstack() kann dieser Multilevel Index in ein Zweidimensionales Datenobjekt umgewandelt werden\n",
    "pop_df = pop.unstack()\n",
    "print(\"\\nDer dazugehörige Dataframe\\n\", pop_df )\n",
    "\n",
    "# pop_df.stack() führt zu dem gegensätzlichen Ergebnis\n",
    "\n",
    "# Variablen ergänzen\n",
    "print(\"\\n Variablen ergänzen\")\n",
    "pop_df = pd.DataFrame({'total': pop,\n",
    "                      'under18': [9267089, 9284094,\n",
    "                                  4687374, 4318033,\n",
    "                                  5906301, 6879014]})\n",
    "print(pop_df)\n",
    "# Rechenoperationen sind weiterhin möglich (unstack() hier optional)\n",
    "print((pop_df['under18']/ pop_df['total']).unstack())\n",
    "\n",
    "# X Mutliindex Daten erstellen\n",
    "print(\"\\nMultiindex DataFrames erstellen\")\n",
    "\n",
    "# Der einfachste Weg ist mit einer eine Liste aus zwei oder mehr Index-Arrays\n",
    "df = pd.DataFrame(np.random.rand(4,2),\n",
    "                 index = [['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                 columns = ['data1', 'data2'])\n",
    "print(df)\n",
    "# auch ein Dictionairy mit Tuples als Keys, werden automatisch von pd.Series() zu einem MultiIndex-Objekt konvertiert\n",
    "\n",
    "# Multiindex Constructors\n",
    "index = pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], [1, 2, 1, 2]]) # erstellt den Index aus einer Liste von Arrays\n",
    "print(index)\n",
    "# index = pd.MultiIndex.from_tuples([('a', 1), ('a', 2) ... ]) möglich\n",
    "\n",
    "index = pd.MultiIndex.from_product([['a', 'b', 'c'], [1, 2]])\n",
    "print(index) # Als Produkt aus den beiden arrays a1, a2, b1, b2 ....\n",
    "\n",
    "# Es ist möglich die Indexe zu benennen\n",
    "print(\"\\n Benannte Indexe\")\n",
    "pop_df.index.names = ['state', 'year']\n",
    "print(pop_df)\n",
    "\n",
    "# Auch Spalten können mit einem Multiindex versehen werden\n",
    "print(\"\\n Komplexe Dataframes mit Mutli-Zeilen- und -Spalten-Index\")\n",
    "index = pd.MultiIndex.from_product([[2013, 2014], [1,2]],\n",
    "                                  names = ['years', 'visit'])\n",
    "columns = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],\n",
    "                                    names = ['Subject', 'Type'])\n",
    "# Daten generieren\n",
    "data = np.round(np.random.randn(4,6), 1)\n",
    "data[:, ::2] *=10\n",
    "data += 37\n",
    "# Dataframe erstellen\n",
    "health_data = pd.DataFrame(data, index=index, columns=columns)\n",
    "print(health_data)\n",
    "# Das Ergebnis ist im Prinzip ein Vierdimensionaler Datensatz mit Personen, Jahr, Typ und Besuchen\n",
    "\n",
    "# Einzelne Personen können ausgewählt werden\n",
    "print(\"\\nEinzelne Person\\n\", health_data[\"Guido\"])\n",
    "print(\"\\nEinzelnes Jahr\\n\", health_data.loc[2013])\n",
    "print(\"\\nEin Jahr einer Person\\n\", health_data.loc[2013][\"Guido\"])\n",
    "\n",
    "\n",
    "# Indexing and Slicing a Multiindex\n",
    "print(\"\\n\\nAuswahl mit Multiindex Series\")\n",
    "# Bei Multiindex Series-Objekten kann der Multindex mit [Index1, Index2] aufgerufen werden\n",
    "print(pop[:, 2000]) # auch pop['California', 2000] für einen Wert oder pop['California': 'New York'] möglich\n",
    "print(\"\\n\", pop[pop > 22000000])\n",
    "\n",
    "# DataFrames\n",
    "print(\"\\nAuswahl bei Multiindex DataFrames\")\n",
    "# Spalten sind in DataFrames primäre Auswahl, somit kann über [Spaltenindex1, Spaltenindex2] eine konkrete Spalte gewählt werden\n",
    "print(health_data['Sue', 'HR'])\n",
    "# implizite Zahlenindex-Auswahl möglich:\n",
    "# - health_data.iloc[:2, :2] > wählt erste vier Zellen aus\n",
    "\n",
    "# Mit loc müssen mehrere Indexe als Tuple angegeben werden\n",
    "print(\"\\n\", health_data.loc[:,('Bob', 'HR')])\n",
    "# Slicing innerhalb eines Tuples führt zu Fehlermeldungen, e.g. health_data.loc[(:, 1), (:, 'HR')] # alle HR in erstem Besuch pro Jahr\n",
    "# >> dafür gibt es pd.IndexSlice\n",
    "idx = pd.IndexSlice\n",
    "print(health_data.loc[idx[:,1], idx[:, 'HR']]) # mit dem IndexSlice Objekt sind die Auswahl von zweitrangigen Indexen möglich\n",
    "\n",
    "# print(health_data.unstack().unstack()) >> kann auch in einen zweidimensionalen DF umgewandelt werden\n",
    "\n",
    "# Sortieren des Indexes\n",
    "print(\"\\nMultilevel Index sortieren\")\n",
    "index = pd.MultiIndex.from_product([['a', 'c', \"b\"], [1, 2]])\n",
    "data = pd.Series(np.random.rand(6), index = index)\n",
    "data.index.names = ['char', 'int']\n",
    "print(data)\n",
    "data.sort_index(inplace=True)\n",
    "print(\"\\n\", data)\n",
    "\n",
    "# dataframe.set_index(['index', 'index2']) # ist eine Möglichkeit daten von wide ins long-Format zu konvertieren\n",
    "\n",
    "# Deskriptive Statistik mit multi-indexed Dataframes\n",
    "print(\"\\nDeskriptive Kennwerte\")\n",
    "print(health_data.mean(axis=0)) # Gibt den Durchschnitt über die Spalten hinweg an\n",
    "print(health_data.groupby(level='years').mean()) # Gibt den Durchschnitt der Jahre an\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8b194771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "    A   B\n",
      "3  A3  B3\n",
      "4  A4  B4\n",
      "\n",
      " Kombinieren mit pd.concat()\n",
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "3  A3  B3\n",
      "4  A4  B4\n",
      "\n",
      "\n",
      "    A   B   C   D\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "\n",
      "Index Dopplung\n",
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "1  A3  B3\n",
      "2  A4  B4\n",
      "Lösung:\n",
      "    A   B\n",
      "0  A1  B1\n",
      "1  A2  B2\n",
      "2  A3  B3\n",
      "3  A4  B4\n",
      "      A   B\n",
      "x 1  A1  B1\n",
      "  2  A2  B2\n",
      "y 1  A3  B3\n",
      "  2  A4  B4\n",
      "     A    B    A    B\n",
      "1   A1   B1  NaN  NaN\n",
      "2   A2   B2  NaN  NaN\n",
      "3  NaN  NaN   A3   B3\n",
      "4  NaN  NaN   A4   B4\n"
     ]
    }
   ],
   "source": [
    "# X Datensätze Kombinieren: Concact und Append (Kurzüberblick)\n",
    "\n",
    "def make_df(cols, ind):\n",
    "    data = {c: [str(c) + str(i) for i in ind] for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "# pd.concat()\n",
    "df1 = make_df('AB', [1, 2])\n",
    "df2 = make_df('AB', [3, 4])\n",
    "\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(\"\\n Kombinieren mit pd.concat()\")\n",
    "print(pd.concat([df1, df2])) # per Default werden Reihen ergänzt\n",
    "print(\"\\n\")\n",
    "df3 = make_df('CD', [1, 2])\n",
    "print(pd.concat([df1, df3], axis=1)) # kann aber auch geändert werden\n",
    "\n",
    "# mit dem Argument ignore_index = True, wird ein neuer kontinuierlicher Index entwickelt, was verhindert, \n",
    "# das Datensätze mit gleicher INdexierung den Index doppeln\n",
    "# Alternative kann mit keys = ['key1', 'key2'] ein Multiindex erstellt werden\n",
    "df2.index = df1.index\n",
    "print('\\nIndex Dopplung')\n",
    "print(pd.concat([df1, df2]))\n",
    "print(\"Lösung:\")\n",
    "print(pd.concat([df1, df2], ignore_index=True))\n",
    "\n",
    "print(pd.concat([df1, df2], keys=['x', 'y']))\n",
    "\n",
    "# Bei unterschiedlichen Spalten/ Zeilen wird der rest mit NA aufgefüllt\n",
    "df2.index = [3,4]\n",
    "print(pd.concat([df1, df2], axis=1))\n",
    "\n",
    "# mit join = \"inner\" kann sichergestellt werden, dass nur Spalten und Zeilen übernommen werden, die in beiden Fällen existieren\n",
    "\n",
    "# X Python unterstützt auch das Kombinieren von datasets auf Basis der relational Algebra (Verwendet in Datenbanken)\n",
    "# pd.merge() vereint verschiedene Kombinationsmöglichkeiten (one-to-one; many-to-one; many-to-many) je nach Input-Daten\n",
    "\n",
    "# one-to-one Join\n",
    "# >> Wenn zwei DF existieren, die eine gemeinsame (Key)Variable enhalten und unterschiedliche Spalten, werden die Werte \n",
    "#    automatisch anhand der gemeinsamen Variable gematcht (e.g. df1: Employer + Gehalt; df2: Employer + Geburtsjahr\n",
    "#    > merge = df3: Emplyer + Gehalt + Geburtsjahr)\n",
    "\n",
    "\n",
    "# many-to-one Join\n",
    "# >> Wenn zwei DF eine Key-Variable enthalten, die in einem der Datensätze mehrfach vorkommt, werden die ergänzten Werte im Merge\n",
    "#    gedoppelt (e.g. df1: Employer-Name + Abteilung(doppelt); df2: Abteilung (Einzeln) + Supervisorname\n",
    "#    > merge: EmployerName + Abteilung + Supervizorname (mehrfach je Abteilung aufgeführt))\n",
    "\n",
    "\n",
    "# many-to-many Join\n",
    "# >> komplex... wenn beide Seiten der Variablen duplikate in der Keyvariable enthalten, werden diese jeweils beim join gedoppelt\n",
    "\n",
    "# Weitere INfos on merge\n",
    "# - in pd.merge() kann mit dem on='variable' Argument die Key-Variable für den merge festgelegt werden >> variable muss in beiden df enthalten sein\n",
    "# - wenn die key-Variable in beiden Datensätzen unterschiedlich benannt wird kann der Name jeweils mit den Argumenten\n",
    "#   left_on='VarName_links' und right_on='VarName_rechts' mitgegeben werden\n",
    "# - wenn man auf Basis des Index mergen will kann left_index = True und right_index=True verwendet werden\n",
    "#   >> .join()-Methode ist ein Merge auf Basis der Indexe\n",
    "# - das how=\"\" Argument beschreibt, wie fehlende Daten gehandhabt werden ('inner' [Default] übernimmt nur vollständige Werte\n",
    "#   in beiden dfs, 'left' = behält linke Einträge und füllt ggf. mit NA, rechts wird entfernt, wenn nicht vollständig\n",
    "#   'right' = umgekehrt left, 'outer' = behält alle Beiträge und füllt fehlende Zellen mit NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "09e566a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planets Dataset \n",
      "Size: (1035, 6) \n",
      "\n",
      "            method  number  orbital_period   mass  distance  year\n",
      "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
      "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
      "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
      "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
      "4  Radial Velocity       1         516.220  10.50    119.47  2009\n",
      "\n",
      "Überblick\n",
      "            number  orbital_period        mass     distance         year\n",
      "count  1035.000000      992.000000  513.000000   808.000000  1035.000000\n",
      "mean      1.785507     2002.917596    2.638161   264.069282  2009.070531\n",
      "std       1.240976    26014.728304    3.818617   733.116493     3.972567\n",
      "min       1.000000        0.090706    0.003600     1.350000  1989.000000\n",
      "25%       1.000000        5.442540    0.229000    32.560000  2007.000000\n",
      "50%       1.000000       39.979500    1.260000    55.250000  2010.000000\n",
      "75%       2.000000      526.005000    3.040000   178.500000  2012.000000\n",
      "max       7.000000   730000.000000   25.000000  8500.000000  2014.000000\n",
      "\n",
      " Einfaches Beispiel\n",
      "  key  data\n",
      "0   A     0\n",
      "1   B     1\n",
      "2   C     2\n",
      "3   A     3\n",
      "4   B     4\n",
      "5   C     5\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002C5219E8E20>\n",
      "     data\n",
      "key      \n",
      "A       3\n",
      "B       5\n",
      "C       7\n",
      "\n",
      "Median der Orbital_Period in Abhängigkeit von der Methode\n",
      "method\n",
      "Astrometry                         631.180000\n",
      "Eclipse Timing Variations         4343.500000\n",
      "Imaging                          27500.000000\n",
      "Microlensing                      3300.000000\n",
      "Orbital Brightness Modulation        0.342887\n",
      "Pulsar Timing                       66.541900\n",
      "Pulsation Timing Variations       1170.000000\n",
      "Radial Velocity                    360.200000\n",
      "Transit                              5.714932\n",
      "Transit Timing Variations           57.011000\n",
      "Name: orbital_period, dtype: float64\n",
      "Astrometry                     shape=(2, 6)\n",
      "Eclipse Timing Variations      shape=(9, 6)\n",
      "Imaging                        shape=(38, 6)\n",
      "Microlensing                   shape=(23, 6)\n",
      "Orbital Brightness Modulation  shape=(3, 6)\n",
      "Pulsar Timing                  shape=(5, 6)\n",
      "Pulsation Timing Variations    shape=(1, 6)\n",
      "Radial Velocity                shape=(553, 6)\n",
      "Transit                        shape=(397, 6)\n",
      "Transit Timing Variations      shape=(4, 6)\n",
      "\n",
      "                                count         mean       std     min      25%  \\\n",
      "method                                                                         \n",
      "Astrometry                       2.0  2011.500000  2.121320  2010.0  2010.75   \n",
      "Eclipse Timing Variations        9.0  2010.000000  1.414214  2008.0  2009.00   \n",
      "Imaging                         38.0  2009.131579  2.781901  2004.0  2008.00   \n",
      "Microlensing                    23.0  2009.782609  2.859697  2004.0  2008.00   \n",
      "Orbital Brightness Modulation    3.0  2011.666667  1.154701  2011.0  2011.00   \n",
      "Pulsar Timing                    5.0  1998.400000  8.384510  1992.0  1992.00   \n",
      "Pulsation Timing Variations      1.0  2007.000000       NaN  2007.0  2007.00   \n",
      "Radial Velocity                553.0  2007.518987  4.249052  1989.0  2005.00   \n",
      "Transit                        397.0  2011.236776  2.077867  2002.0  2010.00   \n",
      "Transit Timing Variations        4.0  2012.500000  1.290994  2011.0  2011.75   \n",
      "\n",
      "                                  50%      75%     max  \n",
      "method                                                  \n",
      "Astrometry                     2011.5  2012.25  2013.0  \n",
      "Eclipse Timing Variations      2010.0  2011.00  2012.0  \n",
      "Imaging                        2009.0  2011.00  2013.0  \n",
      "Microlensing                   2010.0  2012.00  2013.0  \n",
      "Orbital Brightness Modulation  2011.0  2012.00  2013.0  \n",
      "Pulsar Timing                  1994.0  2003.00  2011.0  \n",
      "Pulsation Timing Variations    2007.0  2007.00  2007.0  \n",
      "Radial Velocity                2009.0  2011.00  2014.0  \n",
      "Transit                        2012.0  2013.00  2014.0  \n",
      "Transit Timing Variations      2012.5  2013.25  2014.0  \n",
      "\n",
      "Aggregate\n",
      "    data           \n",
      "     min median max\n",
      "key                \n",
      "A      0    1.5   3\n",
      "B      1    2.5   4\n",
      "C      2    3.5   5\n",
      "                               year  distance\n",
      "method                                       \n",
      "Astrometry                     2013     20.77\n",
      "Eclipse Timing Variations      2012    500.00\n",
      "Imaging                        2013    165.00\n",
      "Microlensing                   2013   7720.00\n",
      "Orbital Brightness Modulation  2013   1180.00\n",
      "Pulsar Timing                  2011   1200.00\n",
      "Pulsation Timing Variations    2007       NaN\n",
      "Radial Velocity                2014    354.00\n",
      "Transit                        2014   8500.00\n",
      "Transit Timing Variations      2014   2119.00\n",
      "\n",
      " Filter\n",
      "     data\n",
      "key      \n",
      "A       3\n",
      "B       5\n",
      "C       7\n",
      "  key  data\n",
      "1   B     1\n",
      "2   C     2\n",
      "4   B     4\n",
      "5   C     5\n",
      "\n",
      " Tranform\n",
      "   data\n",
      "0  -1.5\n",
      "1  -1.5\n",
      "2  -1.5\n",
      "3   1.5\n",
      "4   1.5\n",
      "5   1.5\n"
     ]
    }
   ],
   "source": [
    "# X Aggregation und Grouping\n",
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "print(\"Planets Dataset\", \"\\nSize:\", planets.shape, \"\\n\")\n",
    "print(planets.head())\n",
    "\n",
    "# Deskriptive Überblicksstatitstik mit .describe()\n",
    "print(\"\\nÜberblick\")\n",
    "print(planets.describe()) # mit planets.dropna.describe() werden Zeilen mit fehlenden Werden ausgeschlossen\n",
    "\n",
    "# X GroupBy\n",
    "# Beschreibung der Daten in Abhängigkeit von einer Zielvariable\n",
    "# Intern werden die Daten zunächst anhand der Zielvariable geteilt (split), dann wird eine Berechnung z.B. Mittelwert \n",
    "# durchgeführt (aplly) und das Ergebnis für den Output zusammengesetzt (Combine)\n",
    "\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                  'data':range(6)}, columns=['key', 'data'])\n",
    "print(\"\\n Einfaches Beispiel\")\n",
    "print(df)\n",
    "print(df.groupby('key')) # gibt ein GroupBy Objekt zurück\n",
    "print(df.groupby('key').sum()) # Summiert die Werte anhand der key-Variable\n",
    "\n",
    "# Aggregierte Kennziffern für einzelen Varibalen im Datensatz ausgeben\n",
    "print(\"\\nMedian der Orbital_Period in Abhängigkeit von der Methode\")\n",
    "print(planets.groupby('method')['orbital_period'].median())\n",
    "\n",
    "# >> GroupBy-Objekte sind iterable\n",
    "for(method, group) in planets.groupby('method'):\n",
    "    print(\"{0:30} shape={1}\".format(method, group.shape))\n",
    "# Keine Ahnung, wie der String funktioniert\n",
    "\n",
    "print(\"\\n\", planets.groupby('method')['year'].describe())\n",
    "\n",
    "# - aggregate()\n",
    "# mit aggregate können spezifische Operationen ausgewählt werden\n",
    "print(\"\\nAggregate\")\n",
    "print(df.groupby(\"key\").aggregate(['min', np.median, max]))\n",
    "# erlaubt auch die Auswahl vom Spalten mit Dictionairy\n",
    "print(planets.groupby('method').aggregate({\"year\": max, \"distance\": np.nanmax})) \n",
    "\n",
    "# - filter()\n",
    "# mit filter() können die Ergebnisse auf Basis eines Kriteriums aussortiert werden\n",
    "def filter_func(x):\n",
    "    return x['data'].sum() > 3\n",
    "\n",
    "print(\"\\n Filter\")\n",
    "print(df.groupby('key').sum())\n",
    "print(df.groupby('key').filter(filter_func))\n",
    "# A hat keine Summe > 4 und wird entfernt\n",
    "\n",
    "# - transform()\n",
    "# mit transform() können Datenpunkte verändert werden, e.g. zentrieren der Variable auf Basis von Gruppenmittelwerten\n",
    "print(\"\\n Tranform\")\n",
    "print(df.groupby(\"key\").transform(lambda x: x - x.mean())) # Jedem Wert wird 3 abgezogen, da das der Gruppenmittelwert ist\n",
    "\n",
    "\n",
    "# - aplly()\n",
    "# ... erlaubt eine arbitrary Funktion auf die gruppierten Datensatz anzuwenden\n",
    "\n",
    "# Gruppierung kann auch auf andere Weise stattfinden\n",
    "# - in group apply kann eine Liste der einem Gruppierungsindex mitgegeben werden, die angibt zu welcher Gruppe die Zeilen \n",
    "#   zusammengefasst werden sollen >> muss so lang wie der Datensatz sein\n",
    "# - oder mit df.set_index('key'), kann eine Gruppen Variable festgelegt werden und mit einem Dictionair in \n",
    "#   .groupby({'Ausprägung1': 'Gruppe1', 'Ausprägung2':'Gruppe2', 'Ausprägung3': 'Gruppe1'}) die Gruppenzugeh. definiert werden  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c7d74632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Überblick Titanic-Datensatz\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "Überlebenschance nach Geschlecht\n",
      "sex\n",
      "female    233\n",
      "male      109\n",
      "Name: survived, dtype: int64\n",
      "sex\n",
      "female    0.742038\n",
      "male      0.188908\n",
      "Name: survived, dtype: float64\n",
      "\n",
      "Überlebenschance nach Klasse und Geschlecht\n",
      "class   sex   \n",
      "First   female    0.968085\n",
      "        male      0.368852\n",
      "Second  female    0.921053\n",
      "        male      0.157407\n",
      "Third   female    0.500000\n",
      "        male      0.135447\n",
      "Name: survived, dtype: float64\n",
      "\n",
      "Pivot_table-Lösung\n",
      "class      First    Second     Third\n",
      "sex                                 \n",
      "female  0.968085  0.921053  0.500000\n",
      "male    0.368852  0.157407  0.135447\n",
      "        survived\n",
      "sex             \n",
      "female  0.742038\n",
      "male    0.188908\n",
      "class               First    Second     Third\n",
      "sex    age                                   \n",
      "female (0, 18]   0.909091  1.000000  0.511628\n",
      "       (18, 80]  0.972973  0.900000  0.423729\n",
      "male   (0, 18]   0.800000  0.600000  0.215686\n",
      "       (18, 80]  0.375000  0.071429  0.133663\n",
      "fare            (-0.001, 14.454]                     (14.454, 512.329]  \\\n",
      "class                      First    Second     Third             First   \n",
      "sex    age                                                               \n",
      "female (0, 18]               NaN  1.000000  0.714286          0.909091   \n",
      "       (18, 80]              NaN  0.880000  0.444444          0.972973   \n",
      "male   (0, 18]               NaN  0.000000  0.260870          0.800000   \n",
      "       (18, 80]              0.0  0.098039  0.125000          0.391304   \n",
      "\n",
      "fare                                 \n",
      "class              Second     Third  \n",
      "sex    age                           \n",
      "female (0, 18]   1.000000  0.318182  \n",
      "       (18, 80]  0.914286  0.391304  \n",
      "male   (0, 18]   0.818182  0.178571  \n",
      "       (18, 80]  0.030303  0.192308  \n"
     ]
    }
   ],
   "source": [
    "# X Pivot Tables\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "print(\"Überblick Titanic-Datensatz\")\n",
    "print(titanic.head())\n",
    "print(\"\\nÜberlebenschance nach Geschlecht\")\n",
    "print(titanic.groupby(\"sex\")['survived'].sum())\n",
    "print(titanic.groupby(\"sex\")['survived'].mean())\n",
    "print(\"\\nÜberlebenschance nach Klasse und Geschlecht\")\n",
    "print(titanic.groupby([\"class\", \"sex\"])['survived'].mean())\n",
    "\n",
    "# Das Ergebnis mit pivot_table\n",
    "print(\"\\nPivot_table-Lösung\")\n",
    "print(titanic.pivot_table('survived', index='sex', columns='class'))\n",
    "print(titanic.pivot_table('survived', index='sex'))\n",
    "\n",
    "# Es ist außerdem möglich eine dritte Dimension zu ergänzen\n",
    "age = pd.cut(titanic['age'], [0, 18, 80]) # unterteilt Alter in unter 18 und Älter\n",
    "print(titanic.pivot_table('survived', ['sex', age], 'class'))\n",
    "\n",
    "# Und noch eine vierte Dimension\n",
    "fare = pd.qcut(titanic['fare'], 2) # Teilt den Datensatz in zwei gleichgroße Teile am Medien, siehe print(titanic['fare'].median())\n",
    "print(titanic.pivot_table('survived', [\"sex\", age], [fare, 'class']))\n",
    "\n",
    "# - mit dem Argument aggfunc='mean' (Default), kann der Kennwert, der in der Tabelle ausgegeben wird verändert werden (\"mean\", \"std\" etc.))\n",
    "# - mit margins = True wird der Gesamtwert über alle Gruppen hinweg berechnet und mitausgegeben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1126dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Peter', 'Paul', 'Mary', 'Guido']\n",
      "\n",
      "- Panda-Series data 0    peter\n",
      "1     Paul\n",
      "2     MARY\n",
      "3    gUIDO\n",
      "dtype: object\n",
      "\n",
      "\n",
      "0    Peter\n",
      "1     Paul\n",
      "2     Mary\n",
      "3    Guido\n",
      "dtype: object\n",
      "\n",
      "- Extraktion der ersten Namen mit Regular Expression\n",
      "        0\n",
      "0  Graham\n",
      "1    John\n",
      "2   Terra\n",
      "3    Eric\n",
      "4   Terry\n",
      "5    Mike\n",
      "0    [Graham Chapman]\n",
      "1                  []\n",
      "2     [Terra Gillian]\n",
      "3                  []\n",
      "4       [Terry Jones]\n",
      "5                  []\n",
      "dtype: object\n",
      "\n",
      "Nachnamen\n",
      "0    Chapman\n",
      "1     Cleese\n",
      "2    Gillian\n",
      "3       Idle\n",
      "4      Jones\n",
      "5         Do\n",
      "dtype: object\n",
      "\n",
      "Dummy Kodierung\n",
      "             name   info\n",
      "0  Graham Chapman  B|C|D\n",
      "1     John Cleese    B|D\n",
      "2   Terra Gillian    A|C\n",
      "3       Eric Idle    B|D\n",
      "4     Terry Jones    B|C\n",
      "5         Mike Do  B|C|D\n",
      "   A  B  C  D\n",
      "0  0  1  1  1\n",
      "1  0  1  0  1\n",
      "2  1  0  1  0\n",
      "3  0  1  0  1\n",
      "4  0  1  1  0\n",
      "5  0  1  1  1\n",
      "\n",
      "\n",
      "X Rezepte Beispiel\n",
      "ValueError Trailing data\n",
      "(2, 12)\n",
      "(173278, 17)\n",
      "_id                                {'$oid': '5160756b96cc62079cc2db15'}\n",
      "name                                    Drop Biscuits and Sausage Gravy\n",
      "ingredients           Biscuits\\n3 cups All-purpose Flour\\n2 Tablespo...\n",
      "url                   http://thepioneerwoman.com/cooking/2013/03/dro...\n",
      "image                 http://static.thepioneerwoman.com/cooking/file...\n",
      "ts                                             {'$date': 1365276011104}\n",
      "cookTime                                                          PT30M\n",
      "source                                                  thepioneerwoman\n",
      "recipeYield                                                          12\n",
      "datePublished                                                2013-03-11\n",
      "prepTime                                                          PT10M\n",
      "description           Late Saturday afternoon, after Marlboro Man ha...\n",
      "totalTime                                                           NaN\n",
      "creator                                                             NaN\n",
      "recipeCategory                                                      NaN\n",
      "dateModified                                                        NaN\n",
      "recipeInstructions                                                  NaN\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# X Vectorized String Operations\n",
    "\n",
    "# - Der Weg ohne Panda\n",
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "data_c = [s.capitalize() for s in data]\n",
    "print(data_c)\n",
    "\n",
    "# >> Problem bei fehlenden Werten\n",
    "# data.insert(2, None)\n",
    "# data_c = [s. capitalize() for s in data]\n",
    "\n",
    "# >> Fehlermeldung Attribute ERROR\n",
    "\n",
    "# - mit Panda\n",
    "names = pd.Series(data)\n",
    "print('\\n- Panda-Series data', names)\n",
    "print('\\n')\n",
    "print(names.str.capitalize())\n",
    "\n",
    "# Wie bei arithmetischen Operationen wird die Methode auf alle Elemente des Serienobjekts angewendet\n",
    "\n",
    "# - Panda string-Methoden\n",
    "# .len()            .lower()          .translate()         .islower()\n",
    "# .ljust()          .upper()          .startswith()        .isupper()\n",
    "# .rjust()          .find()           .endswith()          .isnumeric()\n",
    "# .center()         .rfind()          .isalnum()           .isdecimal()\n",
    "# .zfill()          .index()          .isalpha()           .split()\n",
    "# .strip()          .rindex()         .isdigit()           .rsplit()\n",
    "# .rstrip()         .capitalize()     .isspace()           .partition()\n",
    "# .lstrip()         .swapcase()       .istitle()           .rpartition()\n",
    "\n",
    "\n",
    "# X Methoden mit regular Expressions (Denk an Webscraping R)\n",
    "# .match(); .extract(), .findall(), .replace(), .contains(), .count(), .split(), .rsplit()\n",
    "\n",
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terra Gillian', 'Eric Idle', 'Terry Jones', 'Mike Do'])\n",
    "print(\"\\n- Extraktion der ersten Namen mit Regular Expression\")\n",
    "print(monte.str.extract('([A-Za-z]+)'))\n",
    "\n",
    "# Oder komplizierter können alle Namen gefunden werden, die mit einem Konsonanten anfangen (^) und enden ($)\n",
    "print(monte.str.findall(r'^[^AEIOU].*[^aeiou]$'))\n",
    "\n",
    "# - Weitere sinvolle Methoden\n",
    "# .str.get(index)       Indexiert jedes Element (Buchstabe für Buchstabe) und wählt aus\n",
    "# .str.slice(start,end) Indexiert jedes Element und wählt einen Bereich von Buchstaben aus\n",
    "# .str.slice_replace()  Ersetzt Bereich (start,end) durch eine neuen Zeichenkette (replace=\"\")\n",
    "# .str.cat(sep=\" \")     Fügt string zusammen\n",
    "# .str.repeat()             Repeat values\n",
    "# .str.normalize()          Wandelt in Unicode Format\n",
    "# .str.pad()                Fügt Leerzeichen links, rechts oder an beiden Stellen hinzu\n",
    "# .str.wrap()               Teilt lange Strings in Zeilen mit einer gewissen Länge\n",
    "# .str.join()               Fügt strings mit einem separator zusammen\n",
    "# .str.get_dummies()        Extrahiert dummy Variablen als Dataframe\n",
    "\n",
    "\n",
    "# get() kann auch Elemente von Listen auswählen, wie sie z.B. von split zurückgegeben werden\n",
    "print(\"\\nNachnamen\")\n",
    "print(monte.str.split().str.get(-1))\n",
    "\n",
    "# .get_dummies()\n",
    "print(\"\\nDummy Kodierung\")\n",
    "full_monte = pd.DataFrame({'name':monte,\n",
    "                          'info': ['B|C|D', 'B|D', 'A|C', 'B|D', 'B|C', 'B|C|D']})\n",
    "print(full_monte)\n",
    "print(full_monte['info'].str.get_dummies('|'))\n",
    "\n",
    "\n",
    "# X Beispiel - Rezepte Datenbank\n",
    "print(\"\\n\\nX Rezepte Beispiel\")\n",
    "\n",
    "try:\n",
    "    recipes = pd.read_json('recipeitems.json')\n",
    "except ValueError as e:\n",
    "    print(\"ValueError\", e)\n",
    "\n",
    "# >> Ergebnis ist ein Trailing data Error, sagt, dass jede Zeile eine json_Datei ist, aber nicht die Datei\n",
    "\n",
    "with open('recipeitems.json') as f:\n",
    "    line = f.readline()\n",
    "    print(pd.read_json(line).shape)\n",
    "# >> Jede Zeile ist eine json-Datei\n",
    "\n",
    "with open('recipeitems.json', encoding =\"utf8\") as f:\n",
    "    # Extract each line\n",
    "    data = (line.strip() for line in f)\n",
    "    # Reformat, so each Line is the element of a list\n",
    "    data_json =\"[{0}]\".format(','.join(data))\n",
    "# Erebnis als JSON lesen\n",
    "recipes = pd.read_json(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "405f9e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173278, 17)\n",
      "_id                                {'$oid': '5160756b96cc62079cc2db15'}\n",
      "name                                    Drop Biscuits and Sausage Gravy\n",
      "ingredients           Biscuits\\n3 cups All-purpose Flour\\n2 Tablespo...\n",
      "url                   http://thepioneerwoman.com/cooking/2013/03/dro...\n",
      "image                 http://static.thepioneerwoman.com/cooking/file...\n",
      "ts                                             {'$date': 1365276011104}\n",
      "cookTime                                                          PT30M\n",
      "source                                                  thepioneerwoman\n",
      "recipeYield                                                          12\n",
      "datePublished                                                2013-03-11\n",
      "prepTime                                                          PT10M\n",
      "description           Late Saturday afternoon, after Marlboro Man ha...\n",
      "totalTime                                                           NaN\n",
      "creator                                                             NaN\n",
      "recipeCategory                                                      NaN\n",
      "dateModified                                                        NaN\n",
      "recipeInstructions                                                  NaN\n",
      "Name: 0, dtype: object\n",
      "count    173278.000000\n",
      "mean        244.617926\n",
      "std         146.705285\n",
      "min           0.000000\n",
      "25%         147.000000\n",
      "50%         221.000000\n",
      "75%         314.000000\n",
      "max        9067.000000\n",
      "Name: ingredients, dtype: float64\n",
      "\n",
      " Gericht mit der längsten Zutatenliste\n",
      "135598\n",
      "Carrot Pineapple Spice &amp; Brownie Layer Cake with Whipped Cream &amp; Cream Cheese Frosting and Marzipan Carrots\n",
      "\n",
      "Frühstück Rezepte:  3524\n",
      "Rezepte mit Zimt:  10526\n",
      "Schreibfehler Zimt:  11\n",
      "    salt  pepper  oregano   sage  parsley  rosemary  tarragon  thyme  paprika  \\\n",
      "0  False   False    False   True    False     False     False  False    False   \n",
      "1  False   False    False  False    False     False     False  False    False   \n",
      "2   True    True    False  False    False     False     False  False    False   \n",
      "3  False   False    False  False    False     False     False  False    False   \n",
      "4  False   False    False  False    False     False     False  False    False   \n",
      "\n",
      "   cumin  \n",
      "0  False  \n",
      "1  False  \n",
      "2   True  \n",
      "3  False  \n",
      "4  False  \n",
      "\n",
      "Rezepte mit gewählten Gewürzen:  10\n",
      "2069      All cremat with a Little Gem, dandelion and wa...\n",
      "74964                         Lobster with Thermidor butter\n",
      "93768      Burton's Southern Fried Chicken with White Gravy\n",
      "113926                     Mijo's Slow Cooker Shredded Beef\n",
      "137686                     Asparagus Soup with Poached Eggs\n",
      "140530                                 Fried Oyster Po’boys\n",
      "158475                Lamb shank tagine with herb tabbouleh\n",
      "158486                 Southern fried chicken in buttermilk\n",
      "163175            Fried Chicken Sliders with Pickles + Slaw\n",
      "165243                        Bar Tartine Cauliflower Salad\n",
      "Name: name, dtype: object\n",
      "\n",
      "Zutaten für ein Rezept\n",
      " 2 tbsp olive oil\n",
      "1 shallot\n",
      "1 anchovy fillet, chopped \n",
      "½ tsp finely chopped red chilli\n",
      "1 garlic\n",
      "5 king prawns\n",
      "100ml/3½fl oz dry white wine\n",
      "200ml/7¼fl oz fish soup \n",
      "1 tbsp chopped fresh flatleaf parsley\n",
      "1 tbsp persillade (equal quantities of finely chopped garlicparsley\n",
      "1 tbsp breadcrumbs\n",
      "6 garlic cloves\n",
      "1 tbsp Dijon mustard\n",
      "125ml/4½fl oz extra virgin olive oil\n",
      "pinch ground espelette pepper (or pinch paprika and cayenne pepper\n",
      "1 lemon\n",
      "50ml/1¾fl oz sherry vinegar\n",
      "200ml/7¼fl oz olive oil\n",
      "1 tsp Dijon mustard\n",
      "1 shallot\n",
      "2 Little Gem lettuces\n",
      "25g/1oz dandelion\n",
      "1 bunch watercress\n",
      "1 tbsp chopped fresh tarragon\n",
      "1 tbsp chopped fresh chervil\n",
      "1 tbsp chopped fresh mint\n",
      "4 slices toasted sourdough bread\n"
     ]
    }
   ],
   "source": [
    "# X Fortsetzung, da der Code darüber ziemlich lange läd\n",
    "print(recipes.shape) # 173278 Rezepte und 17 Spalten\n",
    "print(recipes.iloc[0])\n",
    "\n",
    "# Die Daten sind ziemlich messy, wie bei webscraping zu erwarten ist...\n",
    "# Z.B. sind die Zustaten als ein String aufgeführt\n",
    "\n",
    "print(recipes.ingredients.str.len().describe()) # im Durchschnitt 244.6 Zeichen\n",
    "print(\"\\n Gericht mit der längsten Zutatenliste\")\n",
    "print(np.argmax(recipes.ingredients.str.len()))\n",
    "print(recipes.name[np.argmax(recipes.ingredients.str.len())])\n",
    "\n",
    "# Weitere Infos für das Arbeiten mit Strings unter:\n",
    "# https://pandas.pydata.org/docs/\n",
    "\n",
    "# Wie viele Rezepte sind in der recipeCategory breakfast\n",
    "print('\\nFrühstück Rezepte: ', recipes.description.str.contains('[Bb]reakfast').sum())\n",
    "print('Rezepte mit Zimt: ', recipes.ingredients.str.contains('[Cc]innamon').sum())\n",
    "print('Schreibfehler Zimt: ', recipes.ingredients.str.contains('[Cc]inamon').sum())\n",
    "\n",
    "\n",
    "# Einfache Rezept-Recommander\n",
    "spice_list = ['salt', 'pepper', 'oregano', 'sage', 'parsley', 'rosemary', 'tarragon', 'thyme', 'paprika', 'cumin']\n",
    "\n",
    "import re\n",
    "spice_df = pd.DataFrame(\n",
    "    dict((spice, recipes.ingredients.str.contains(spice, re.IGNORECASE))\n",
    "        for spice in spice_list))\n",
    "# Dict mapped den Name des Spices zu dem ERgebnis der Contains Funktion... AUf Basis des Dictionairys wird dann ein Datensatz erstellt\n",
    "print(spice_df.head())\n",
    "selection = spice_df.query('parsley & paprika & tarragon')\n",
    "print('\\nRezepte mit gewählten Gewürzen: ', len(selection))\n",
    "\n",
    "print(recipes.name[selection.index]) # Rezepte\n",
    "print(\"\\nZutaten für ein Rezept\\n\", recipes.ingredients[2069])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda Timeseries Data\n",
    "# nachlesen unter >>> pandas.pydata.org/docs >> timeseries\n",
    "\n",
    "\n",
    "# Besondere Funktionen - .eval und und .query\n",
    "# mit pd.eval('df1 + df2 + df3 + df4') können Datensätze schnell zusammengerechnet werden\n",
    "# >> Damit können Arithmetische Operationen, Vergleiche sowie Operationen mit Attributen und Indexen durchgeführt werden \n",
    "#    (z.B. pd.eval('df.T[0] +df3.iloc[0]'))\n",
    "\n",
    "# >> Datensätze haben ebenfalls eine .eval() Funktion, dann muss der Datensatz nicht mehr spezifiert werden\n",
    "#    und es kann dierekt auf die Spalten zugegriffen werden\n",
    "\n",
    "# mit df.eval('D = (A + B)/C', inplace=True) # könnte eine neue Spalte im Datensatz ergänzt werden aus ABC-berechnet\n",
    "# mit df.val('D = A + @columnmean', inplace=True) # kann auf eine lokale Variable für die Berechnung zugegriffen werden\n",
    "\n",
    "# .query ist eine andere Funktion, die bei highperformance Operationen nützlich sein kann\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
